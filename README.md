 NM-Project
 This project aims to develop a robust speech-to-text transcription system capable of accurately transcribing speech in noisy environments. Background noise, such as ambient chatter, machinery sounds, and reverberation, often degrades the performance of traditional Automatic Speech Recognition (ASR) systems. To address this challenge, we propose a multi-faceted approach that combines advanced machine learning techniques with noise-robust feature extraction methods.

Our system leverages deep neural networks (DNNs) trained on a diverse dataset augmented with various real-world noise conditions. By incorporating noise augmentation during training, the model learns to generalize better to unseen noisy environments, thereby improving transcription accuracy. Additionally, we implement feature enhancement techniques, such as Cepstral Mean and Variance Normalization (CMVN), to mitigate the effects of noise on acoustic features.
 TEAM  MEMBERS
 DHIVYA PRATHA.R
 DIVYA DHARSHINI.A
 ELAMPIRAI.E
 KAVIYA.S
